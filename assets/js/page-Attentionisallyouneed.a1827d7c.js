(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{523:function(t,e,r){"use strict";r.r(e);var a=r(1),s=Object(a.a)({},(function(){var t=this,e=t.$createElement,r=t._self._c||e;return r("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[r("h2",{attrs:{id:"摘要"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#摘要"}},[t._v("#")]),t._v(" 摘要")]),t._v(" "),r("ul",[r("li",[t._v("Transformer，一个新的网络架构，只使用注意力机制(attention mechanism)，完全没用循环和卷积")]),t._v(" "),r("li",[t._v("对于机器翻译任务，性能表现更好，可并行度更高，训练时间大量减少")]),t._v(" "),r("li",[t._v("可以泛化到其它任务上")]),t._v(" "),r("li",[r("a",{attrs:{href:"https://github.com/tensorflow/tensor2tensor",target:"_blank",rel:"noopener noreferrer"}},[t._v("代码实现"),r("OutboundLink")],1)])]),t._v(" "),r("h2",{attrs:{id:"结论"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#结论"}},[t._v("#")]),t._v(" 结论")]),t._v(" "),r("ul",[r("li",[t._v("Transformer是第一个完全用注意力机制的序列转录模型(sequence transduction model)，它将encoder-decoder架构中最常用的循环层(recurrent layers)替换成multi-headed self-attention。")]),t._v(" "),r("li",[t._v("对于机器翻译任务，确实性能表现更好，训练时间更少")]),t._v(" "),r("li",[t._v("作者认为Transformer不仅可以应用到文本处理上，在图像，语音，视频上应该也可行。让生成不那么时序化也是另一个研究方向。")])]),t._v(" "),r("h2",{attrs:{id:"导言"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#导言"}},[t._v("#")]),t._v(" 导言")]),t._v(" "),r("ul",[r("li",[t._v("循环模型最主要的缺点是难以并行化，训练时间长。因为它要计算序列的隐藏状态h"),r("sub",[t._v("t")]),t._v("时，必须先计算h"),r("sub",[t._v("t-1")]),t._v("。")]),t._v(" "),r("li",[t._v("已经有人将attention机制应用于encoder-decoder架构了，但是是和循环模型一起使用的。")]),t._v(" "),r("li",[t._v("我们只用attention机制，效果更好")])]),t._v(" "),r("h2",{attrs:{id:"相关工作"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#相关工作"}},[t._v("#")]),t._v(" 相关工作")]),t._v(" "),r("ul",[r("li",[t._v("有人试过用CNN来改进RNN，但这样做的缺点是序列相隔比较远的像素产生联系很难，用transformer就很容易了。但CNN有和好处是可以有多个输出通道，所以作者又提出了multi-headed self-attention用来模拟CNN的多输出通道的效果。")]),t._v(" "),r("li",[t._v("self-attention机制不是作者的创新，相关工作已经有了。")]),t._v(" "),r("li",[t._v("作者的创新在于在encoder-decoder架构中只使用self-attention机制。")])]),t._v(" "),r("h2",{attrs:{id:"模型架构"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#模型架构"}},[t._v("#")]),t._v(" ==模型架构==")])])}),[],!1,null,null,null);e.default=s.exports}}]);