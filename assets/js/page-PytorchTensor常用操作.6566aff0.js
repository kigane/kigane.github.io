(window.webpackJsonp=window.webpackJsonp||[]).push([[40],{570:function(t,s,a){"use strict";a.r(s);var n=a(1),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h2",{attrs:{id:"可重复性"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#可重复性"}},[t._v("#")]),t._v(" 可重复性")]),t._v(" "),a("ul",[a("li",[t._v("np.random.seed(seed) 设置NumPy的全局RNG种子")]),t._v(" "),a("li",[t._v("torch.manual_seed(seed) 设置CPU和CUDA的RNG种子")]),t._v(" "),a("li",[t._v("if torch.cuda.is_available():")]),t._v(" "),a("li",[t._v("torch.cuda.manual_seed(42)")]),t._v(" "),a("li",[t._v("torch.cuda.manual_seed_all(42)")]),t._v(" "),a("li",[t._v("torch.backends.cudnn.benchmark = False 固定cuDNN在程序运行时使用的卷积算法")]),t._v(" "),a("li",[t._v("torch.backends.cudnn.deterministic = True  程序运行时设定的算法也可能不同，将其确定下来")])]),t._v(" "),a("h2",{attrs:{id:"创建张量"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#创建张量"}},[t._v("#")]),t._v(" 创建张量")]),t._v(" "),a("ul",[a("li",[t._v("torch.tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False) 总是会复制data")]),t._v(" "),a("li",[t._v("torch.Tensor(shape/data), torch.rand(shape),torch.randn(shape) 默认生成FloatTensor")]),t._v(" "),a("li",[t._v("和numpy数组相互转换\n"),a("ul",[a("li",[t._v("some_tensor = torch.from_numpy(np_ary) 不会复制data，共享存储")]),t._v(" "),a("li",[t._v("some_tensor = torch.as_tensor(data, dtype=None, device=None) 如果dtype一致，则不会复制data")]),t._v(" "),a("li",[t._v("np_ary = some_tensor.cpu().numpy() # tensor需要在CPU上")])])]),t._v(" "),a("li",[t._v("转换为list\n"),a("ul",[a("li",[t._v("lst = some_tensor.tolist()")]),t._v(" "),a("li",[t._v("some_tensor = torch.tensor(lst)")])])]),t._v(" "),a("li",[t._v("张量数据类型的转换\n"),a("ul",[a("li",[t._v("some_tensor.item() 当Tensor只有一个元素时，返回相应的python原生对象")]),t._v(" "),a("li",[t._v("some_tensor.long()")]),t._v(" "),a("li",[t._v("some_tensor.int()")]),t._v(" "),a("li",[t._v("some_tensor.short()")]),t._v(" "),a("li",[t._v("some_tensor.bool()")]),t._v(" "),a("li",[t._v("some_tensor.half() 半精度浮点型")]),t._v(" "),a("li",[t._v("some_tensor.float()")]),t._v(" "),a("li",[t._v("some_tensor.double()")]),t._v(" "),a("li",[t._v("...")]),t._v(" "),a("li",[t._v("some_tensor.to(torch.int)")]),t._v(" "),a("li",[t._v("a.type_as(b) 将a的数据类型转换为b的数据类型")])])]),t._v(" "),a("li",[t._v("改变数据存储位置\n"),a("ul",[a("li",[t._v("some_tensor.to(device)")]),t._v(" "),a("li",[t._v("some_tensor.cuda()")]),t._v(" "),a("li",[t._v("some_tensor.cpu()")])])]),t._v(" "),a("li",[t._v("不参与求导\n"),a("ul",[a("li",[t._v("some_tensor.detach()")]),t._v(" "),a("li",[t._v("some_tensor.requires_grad_(False)")])])]),t._v(" "),a("li",[t._v("两个张量比较的结果是一个bool类型的张量")])]),t._v(" "),a("h2",{attrs:{id:"改变张量形状"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#改变张量形状"}},[t._v("#")]),t._v(" 改变张量形状")]),t._v(" "),a("ul",[a("li",[t._v("some_tensor.view(shape)")]),t._v(" "),a("li",[t._v("some_tensor.reshape(shape)")]),t._v(" "),a("li",[t._v("some_tensor.permute()")])]),t._v(" "),a("h2",{attrs:{id:"矩阵相乘与点积"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#矩阵相乘与点积"}},[t._v("#")]),t._v(" 矩阵相乘与点积")]),t._v(" "),a("ul",[a("li",[t._v("torch.mv(mat, vec) 矩阵乘向量，不会广播")]),t._v(" "),a("li",[t._v("torch.matmul(a, b) == "),a("code",[t._v("a @ b")]),t._v(" 矩阵相乘")]),t._v(" "),a("li",[t._v("torch.mm(a, b) 矩阵相乘")]),t._v(" "),a("li",[t._v("torch.bmm(a, b) 批量相乘。(b, n, m)x(b, m, p)->(b, n, p)")]),t._v(" "),a("li",[t._v("torch.dot(x, y)")])]),t._v(" "),a("h2",{attrs:{id:"广播机制"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#广播机制"}},[t._v("#")]),t._v(" 广播机制")]),t._v(" "),a("ul",[a("li",[t._v("每个张量必须至少有1维")]),t._v(" "),a("li",[t._v("维数遍历是从最后一维开始的，可广播的条件是，两个张量相应的维度\n"),a("ul",[a("li",[t._v("相等")]),t._v(" "),a("li",[t._v("其中一个是1")]),t._v(" "),a("li",[t._v("其中一个不存在")])])]),t._v(" "),a("li",[t._v("其中\n"),a("ul",[a("li",[t._v("相等，就是正常情况")]),t._v(" "),a("li",[t._v("其中一个不存在时，就加一维，令其成为1")]),t._v(" "),a("li",[t._v("其中一个为1，会将其复制扩张到另一个张量的大小")])])])]),t._v(" "),a("h2",{attrs:{id:"squeeze-unsqueeze"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#squeeze-unsqueeze"}},[t._v("#")]),t._v(" squeeze/unsqueeze")]),t._v(" "),a("ul",[a("li",[t._v("torch.squeeze(input, dim=None, *, out=None) → Tensor")]),t._v(" "),a("li",[t._v("torch.Tensor.squeeze(dim=None)")]),t._v(" "),a("li",[t._v("squeeze将指定维度去除(维度必须大小为1，否则无事发生)，如果没有指定dim，则去除所有大小为1的维度")]),t._v(" "),a("li",[t._v("unsqueeze在指定维度前添加一个新维度(大小为1)")])]),t._v(" "),a("h2",{attrs:{id:"torch-max"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#torch-max"}},[t._v("#")]),t._v(" torch.max")]),t._v(" "),a("ul",[a("li",[t._v("torch.sum() 机制类似torch.max，当然，没有参数为两个张量的sum")]),t._v(" "),a("li",[t._v("torch.Tensor.sum() 功能和torch.sum()相同，只是原来的第一个位置参数变成了用来调用sum()的对象")])]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("a "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("arange"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nb "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("arange"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shuffle"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nb "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_numpy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 求整个张量的最大值")]),t._v("\nret1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# tensor(23)")]),t._v("\nret1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 23")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 求指定维度上的最大值，并且指定维度会消失(维度==>值)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# values: 记录最大值")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# indices: 记录最大值在原维度的位置索引")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# keepdim=True: 会保持原维度。其行为相当于在指定维度会保留一个元素")]),t._v("\nvalues"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" indices "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nvalues"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" indices "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nvalues"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" indices "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" keepdim"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nvalues"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" indices "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" keepdim"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 比较两个张量，返回一个由两个数组中更大的元素组成的新张量")]),t._v("\nc "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\ntensor([[[ 8, 16,  2, 18],\n         [11,  9, 13,  7],\n         [21,  9, 10, 12]],\n\n        [[15, 13, 14, 22],\n         [17, 20, 23, 19],\n         [20, 21, 22, 23]]])\n"""')]),t._v("\n\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br"),a("span",{staticClass:"line-number"},[t._v("24")]),a("br"),a("span",{staticClass:"line-number"},[t._v("25")]),a("br"),a("span",{staticClass:"line-number"},[t._v("26")]),a("br"),a("span",{staticClass:"line-number"},[t._v("27")]),a("br"),a("span",{staticClass:"line-number"},[t._v("28")]),a("br"),a("span",{staticClass:"line-number"},[t._v("29")]),a("br"),a("span",{staticClass:"line-number"},[t._v("30")]),a("br"),a("span",{staticClass:"line-number"},[t._v("31")]),a("br"),a("span",{staticClass:"line-number"},[t._v("32")]),a("br"),a("span",{staticClass:"line-number"},[t._v("33")]),a("br"),a("span",{staticClass:"line-number"},[t._v("34")]),a("br"),a("span",{staticClass:"line-number"},[t._v("35")]),a("br")])]),a("h2",{attrs:{id:"cat"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#cat"}},[t._v("#")]),t._v(" cat")]),t._v(" "),a("ul",[a("li",[t._v("torch.cat(tensors, dim=0, *, out=None) -> Tensor")]),t._v(" "),a("li",[t._v("tensors中每个tensor必须除了指定维度外，其他维度大小一致。")])]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("randn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntorch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (6, 3)")]),t._v("\ntorch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (2, 9)")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("h2",{attrs:{id:"stack"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#stack"}},[t._v("#")]),t._v(" stack")]),t._v(" "),a("ul",[a("li",[t._v("torch.stack(tensors, dim=0, *, out=None) → Tensor")]),t._v(" "),a("li",[t._v("tensors中每个tensor维度大小必须一致")]),t._v(" "),a("li",[t._v("在新维度将所有tensor合并起来")]),t._v(" "),a("li",[a("code",[t._v("torch.stack(tensors, dim=n) == torch.cat([torch.unsqueeze(t, dim=n) for t in tensors], dim=n)")])])]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("randn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntorch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stack"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (3, 2, 4)")]),t._v("\ntorch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stack"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (2, 3, 4)")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("h2",{attrs:{id:"linspace"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#linspace"}},[t._v("#")]),t._v(" linspace")]),t._v(" "),a("ul",[a("li",[t._v("torch.linspace(start, end, steps, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor")]),t._v(" "),a("li",[t._v("结果包含start，end共计steps个元素。"),a("code",[t._v("[start, ... , end]")])]),t._v(" "),a("li",[t._v("torch.linspace(3, 10, steps=5) # tensor([  3.0000,   4.7500,   6.5000,   8.2500,  10.0000])")])]),t._v(" "),a("h2",{attrs:{id:"randperm"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#randperm"}},[t._v("#")]),t._v(" randperm")]),t._v(" "),a("ul",[a("li",[t._v("torch.randperm(n, *, generator=None, out=None, dtype=torch.int64, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) → Tensor")]),t._v(" "),a("li",[t._v("返回从0到n-1的一个随机排列")])])])}),[],!1,null,null,null);s.default=e.exports}}]);