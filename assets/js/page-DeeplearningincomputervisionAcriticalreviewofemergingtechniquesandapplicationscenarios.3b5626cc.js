(window.webpackJsonp=window.webpackJsonp||[]).push([[19],{515:function(e,t,a){"use strict";a.r(t);var o=a(1),n=Object(o.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"deep-learning-in-computer-vision-a-critical-review-of-emerging-techniques-and-application-scenarios"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#deep-learning-in-computer-vision-a-critical-review-of-emerging-techniques-and-application-scenarios"}},[e._v("#")]),e._v(" Deep learning in computer vision: A critical review of emerging techniques and application scenarios")]),e._v(" "),a("p",[a("a",{attrs:{href:"https://www.sciencedirect.com/science/article/pii/S2666827021000670",target:"_blank",rel:"noopener noreferrer"}},[e._v("原文"),a("OutboundLink")],1)]),e._v(" "),a("h2",{attrs:{id:"abstract"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#abstract"}},[e._v("#")]),e._v(" abstract")]),e._v(" "),a("p",[e._v("八大新兴技术，四大应用场景。")]),e._v(" "),a("p",[e._v("深度学习在过去十年中发展迅速，就算法与架构而言，可分为十个主要类别：")]),e._v(" "),a("ol",[a("li",[e._v("Convolutional Neural Networks (CNNs)")]),e._v(" "),a("li",[e._v("Long Short-Term Memory Networks (LSTMs)")]),e._v(" "),a("li",[e._v("Recurrent Neural Networks (RNNs)")]),e._v(" "),a("li",[e._v("Generative Adversarial Networks (GANs)")]),e._v(" "),a("li",[e._v("Radial Basis Function Networks (RBFNs)")]),e._v(" "),a("li",[e._v("Multilayer Perceptrons (MLPs)")]),e._v(" "),a("li",[e._v("Self-Organizing Maps (SOMs)")]),e._v(" "),a("li",[e._v("Deep Belief Networks (DBNs)")]),e._v(" "),a("li",[e._v("Restricted Boltzmann Machines (RBMs)")]),e._v(" "),a("li",[e._v("Autoencoders")])]),e._v(" "),a("p",[e._v("对比RBM, Autoencoders, Sparse Coding和CNN后，最终得出的结论，在CV领域，CNN是最合适的架构"),a("sup",{staticClass:"footnote-ref"},[a("a",{attrs:{href:"#footnote1"}},[e._v("[1]")]),a("a",{staticClass:"footnote-anchor",attrs:{id:"footnote-ref1"}})]),e._v("。")]),e._v(" "),a("h2",{attrs:{id:"八大技术"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#八大技术"}},[e._v("#")]),e._v(" 八大技术")]),e._v(" "),a("h3",{attrs:{id:"alexnet"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#alexnet"}},[e._v("#")]),e._v(" AlexNet")]),e._v(" "),a("p",[e._v("由Krizhevsky"),a("sup",{staticClass:"footnote-ref"},[a("a",{attrs:{href:"#footnote2"}},[e._v("[2]")]),a("a",{staticClass:"footnote-anchor",attrs:{id:"footnote-ref2"}})]),e._v("等(2012)提出的AlexNet的架构为：5层卷积层(convolutional layer)，后跟3层连接层(connected layer)。每个卷积层的输出都会使用ReLU作为激活函数。AlexNet的原始模型用两块GPU训练。一个就称为AlexNet, 另一个称为CaffeNet，主要的区别在于使用pooling的位置不同，CaffeNet是在前两个卷积层的局部响应标准化之前，而AlexNet正相反。")]),e._v(" "),a("h3",{attrs:{id:"vggnet"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#vggnet"}},[e._v("#")]),e._v(" VGGNet")]),e._v(" "),a("p",[e._v("由Simonyan and Zisserman (2015)"),a("sup",{staticClass:"footnote-ref"},[a("a",{attrs:{href:"#footnote3"}},[e._v("[3]")]),a("a",{staticClass:"footnote-anchor",attrs:{id:"footnote-ref3"}})]),e._v(" 提出的VGGNet，通过使用小的卷积filter(3×3)添加更多卷积层来增加网络的深度，同时其他参数是固定的。在现有配置能达到的前提下，将网络深度增加到16层和19层时，效果最好，因此特定架构被称为VGG-16和VGG-19。VGGNet优于同期其他方法的原因是，VGGNet的参数空间特别大，其最终模型有超过5亿个参数，作为对比，AlexNet只有两亿个参数。")]),e._v(" "),a("h3",{attrs:{id:"googlenet-inception"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#googlenet-inception"}},[e._v("#")]),e._v(" GoogLeNet & Inception")]),e._v(" "),a("p",[e._v("Lin等人介绍了Network-in-Network(NIN)，它由一堆 mlpconv 层组成，用一般非线性函数逼近器(general non-linear function approximator)代替卷积filter。NIN的另一个特点是它使用global average pooling来代替全连接层。它平均每个feature map，并将结果直接导入softmax层。在某些数据集中，NIN可以使用很少的参数达到和之前差不多甚至更好的识别准确率。")]),e._v(" "),a("p",[e._v("Szegedy et al. (2015)提出了一种新的CNN架构，如图所示。"),a("br"),e._v(" "),a("img",{attrs:{src:"/assets/thesis/Inception.png",alt:"pic"}}),a("br"),e._v("\n其目标是在保持计算量恒定的同时，增加网络的宽度和深度。GoogLeNet这个22层的模型，多次使用了Inception层。GoogLeNet主要利用了NIN的两个idea：1x1的卷积和global average pooling。"),a("br"),e._v("\n后来，Szegedy发现，卷积核越大，计算代价就越大，且是超乎寻常的大。因此，使用两个3x3的卷积核代替5x5(7x7)的卷积核。"),a("br"),e._v("\n在v3版本，又使用了Batch Normalization。"),a("br"),e._v("\n受ResNet启发，他们将Inception架构与残差连接相结合，创造了一个名为Inception-ResNet的新架构。"),a("br"),e._v("\n最终，Chollet (2017)提出Xception架构。")]),e._v(" "),a("h3",{attrs:{id:"resnet"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#resnet"}},[e._v("#")]),e._v(" ResNet")]),e._v(" "),a("p",[e._v("学习考虑输入的残差函数比学习没有用到输入的参数更高效。残差神经网络使用多个参数层来学习输入输出之间的残差表示，而非像普通CNN那样直接学习输入输出之间的映射。")]),e._v(" "),a("h3",{attrs:{id:"densenet"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#densenet"}},[e._v("#")]),e._v(" DenseNet")]),e._v(" "),a("p",[e._v("将所有layer直接相连，每一个layer的输入来自其前面的所有layer。")]),e._v(" "),a("h3",{attrs:{id:"mobilenet"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mobilenet"}},[e._v("#")]),e._v(" MobileNet")]),e._v(" "),a("h3",{attrs:{id:"efficientnet"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#efficientnet"}},[e._v("#")]),e._v(" EfficientNet")]),e._v(" "),a("p",[e._v("保持网络深度，宽度，resolution的均衡会使模型的表现更好。")]),e._v(" "),a("h3",{attrs:{id:"regnet"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#regnet"}},[e._v("#")]),e._v(" RegNet")]),e._v(" "),a("p",[e._v("一个网络设计范式，结合了手工设计和NAS(network architecture search)的优点。")]),e._v(" "),a("hr",{staticClass:"footnotes-sep"}),e._v(" "),a("section",{staticClass:"footnotes"},[a("ol",{staticClass:"footnotes-list"},[a("li",{staticClass:"footnote-item",attrs:{id:"footnote1"}},[a("p",[e._v("Guo, Y., Liu, Y., Oerlemans, A., Lao, S., Wu, S., & Lew, M. S. (2016). Deep learning for visual understanding: A review. Neurocomputing, 187, 27–48. http://dx.doi.org/10.1016/j.neucom.2015.09.116. "),a("a",{staticClass:"footnote-backref",attrs:{href:"#footnote-ref1"}},[e._v("↩︎")])])]),e._v(" "),a("li",{staticClass:"footnote-item",attrs:{id:"footnote2"}},[a("p",[e._v("Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. In Proceedings of the 25th international conference on neural information processing systems (nips), Vol. 1, USA (pp. 1097-1105). "),a("a",{staticClass:"footnote-backref",attrs:{href:"#footnote-ref2"}},[e._v("↩︎")])])]),e._v(" "),a("li",{staticClass:"footnote-item",attrs:{id:"footnote3"}},[a("p",[e._v("Simonyan, K., & Zisserman, A. (2015). Very deep convolutional networks for largescale image  recognition. In Proceedings of the 3rd international conference on learning representations (iclr2015), USA. "),a("a",{staticClass:"footnote-backref",attrs:{href:"#footnote-ref3"}},[e._v("↩︎")])])])])])])}),[],!1,null,null,null);t.default=n.exports}}]);